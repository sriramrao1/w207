# This tells matplotlib not to try opening a new window for each plot.
%matplotlib inline

# General libraries.
import re
import numpy as np
import matplotlib.pyplot as plt
import operator.add as 

# SK-learn libraries for learning.
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.grid_search import GridSearchCV

# SK-learn libraries for evaluation.
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from sklearn.metrics import classification_report

# SK-learn library for importing the newsgroup data.
from sklearn.datasets import fetch_20newsgroups

# SK-learn libraries for feature extraction from text.
from sklearn.feature_extraction.text import *
------------------------------------------------------------
categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']
newsgroups_train = fetch_20newsgroups(subset='train',
                                      remove=('headers', 'footers', 'quotes'),
                                      categories=categories)
newsgroups_test = fetch_20newsgroups(subset='test',
                                     remove=('headers', 'footers', 'quotes'),
                                     categories=categories)

num_test = len(newsgroups_test.target)
test_data, test_labels = newsgroups_test.data[int(num_test/2):], newsgroups_test.target[int(num_test/2):]
dev_data, dev_labels = newsgroups_test.data[:int(num_test/2)], newsgroups_test.target[:int(num_test/2)]
train_data, train_labels = newsgroups_train.data, newsgroups_train.target

print('training label shape:', train_labels.shape)
print('test label shape:', test_labels.shape) 
print('dev label shape:', dev_labels.shape) 
print('labels names:', newsgroups_train.target_names) 

---------------------------------------------------
#def P1(num_examples=5):
### STUDENT START ###
for i in range (1,5):
    print(i, " - Chat Message Content")
    print(train_data[i])
    if (train_labels[i] == 0):
        print('Label is alt.atheism');
    if (train_labels[i] == 1):
        print('Label is comp.graphics');
    if (train_labels[i] == 2):
        print('Label is sci.space');
    if (train_labels[i] == 3):
        print('Label is talk.religion.misc');
    print("-------------------------------------------------------------------------------")
### STUDENT END ###
#P1(2)
------------------------------------------------------
#def P2():
### STUDENT START ###
#def add(a, b):
#    return int(a) + int(b)

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(train_data)
numsamples = X.shape[0]
vocabsize = X.shape[1]
nonzerofeatures = X.nnz
#print("P2 a - ",X.shape)
#vocab = vectorizer.vocabulary_
#vocabsize = len(vocab)
# a. What is the size of the vocabulary?
#print("P2 a - Size of the vocabulary is", vocabsize)
print("P2 a - Size of the vocabulary is", vocabsize)
print("P2 a - nonzerofeatures is", nonzerofeatures)

# a. What is the average number of non-zero features per example?
print("P2 a - Average number of non-zero features per example is", nonzerofeatures/numsamples)

# a.  What fraction of the entries in the matrix are non-zero? ---- VALIDATE if nnz is for the entire matrix
print("P2 a - fraction of the entries in the matrix that are non-zero is", (nonzerofeatures/numsamples)/vocabsize)

# b. What are the 0th and last feature strings (in alphabetical order)? 
# Hint: use the vectorizer's get_feature_names function.
featurename = vectorizer.get_feature_names();
print("P2 b - First Feature Name", featurename[0])
print("P2 b - Last Feature Name", featurename[len(featurename)-1])

# c. Now what's the average number of non-zero features per example? ---- PENDING
p2cvocab = ["atheism", "graphics", "space", "religion"]
p2cvectorizer = CountVectorizer(min_df=1, vocabulary=p2cvocab)
p2cX = p2cvectorizer.fit_transform(train_data)
p2cnumsamples = p2cX.shape[0]
p2cvocabsize = p2cX.shape[1]
p2cnonzerofeatures = p2cX.nnz
#p2vocabsize = len(p2vocab)
print("P2 c - Average number of non-zero features per example is", p2cnonzerofeatures/p2cnumsamples)

# d. What size vocabulary does this yield?
p2dvectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\b\w+\b', min_df=1)
#analyze = p2dvectorizer.build_analyzer()
p2dX = p2dvectorizer.fit_transform(train_data)
p2dvocabsize = p2dX.shape[1]
print("P2 d - Size of the vocabulary is", p2dvocabsize)

# e.  Use the "min_df" argument to prune words that appear in fewer than 10 documents. What size vocabulary does this yield?
p2evectorizer = CountVectorizer(min_df=10)
p2eX = p2evectorizer.fit_transform(train_data)
p2evocabsize = p2eX.shape[1]
#p2evocab = p2evectorizer.vocabulary_
#p2evocabsize = len(p2evocab)
print("P2 e - Size of the vocabulary is", p2evocabsize)

# f. Using the standard CountVectorizer, what fraction of the words in the dev data are missing from the vocabulary? 
# Hint: build a vocabulary for both train and dev and look at the size of the difference.
p2fvectorizer = CountVectorizer()
p2fX = p2fvectorizer.fit_transform(dev_data)
p2fvocabsize = p2fX.shape[1]

print("P2 f - fraction of dev data missing from the vocab", (p2fvocabsize-vocabsize)/vocabsize)
### STUDENT END ###
#P2()
--------------------------------------------------------------
#def P3():
### STUDENT START ###
p3vectorizer = CountVectorizer()
p3train_data = p3vectorizer.fit_transform(train_data)

# Use the same vectorizer as the training data, so that the same vocabulary is used
p3dev_data = p3vectorizer.transform(dev_data)

# Print the shape attributes to check if the same vocabulary is used
#print(p3train_data.shape)
#print(p3dev_data.shape)

#print('training label shape:', train_labels.shape)
#print('test label shape:', test_labels.shape) 
#print('dev label shape:', dev_labels.shape) 
#print(train_labels)
KNclf = KNeighborsClassifier(n_neighbors=100)
# Train the model with the training data set 
KNclf.fit(p3train_data, train_labels)
# Make predictions for the data in dev dataset 
prediction = KNclf.predict(p3dev_data)
# Compare predicted labels with actual labels
#print("p3 KNeighborsClassifier accuracy is ", KNclf.score(p3dev_data, dev_labels));
print("P3 F1 score for K Nearest Neighbors algorithm is ", metrics.f1_score(dev_labels, prediction, average='macro'))  

      
parameters = [{'n_neighbors':[1,3,5,10,20,50,100,1000]}]
KNGclf = GridSearchCV(KNeighborsClassifier(weights='distance'), parameters)
KNGclf.fit(p3train_data,train_labels)
#KNclf = GridSearchCV(KNeighborsClassifier(n_neighbors))
#CVclf.fit(train_data,train_labels) 
# Print the best estimator
print(KNGclf.best_estimator_)
# Print the best score
print(KNGclf.best_score_)
# Print the best alpha
print(KNGclf.best_params_)
# Print the grid scores for all alpha values
print(KNGclf.grid_scores_)


# Train the MultinomialNB classifier with the training data
parameters = [{'alpha':[0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}]
MNBclf = GridSearchCV(MultinomialNB(class_prior=None, fit_prior=True), parameters)
MNBclf.fit(p3train_data,train_labels)

# Print the best estimator
print(MNBclf.best_estimator_)
# Print the best score
print(MNBclf.best_score_)
# Print the best alpha
print(MNBclf.best_params_)
# Print the grid scores for all alpha values
#print(MNBclf.grid_scores_)

#MNBclf = MultinomialNB()
#MNBclf.fit(p3train_data, train_labels)
#MNBprediction = MNBclf.predict(p3dev_data)
# Compare predicted labels with actual labels
#MNBaccuracy = MNBclf.score(p3dev_data, dev_labels)
#print("Predicted accuracy for MultinomialNB is "+str(MNBaccuracy))

#Get the baseline F1
LRclf = LogisticRegression(C=0.1)
LRclf.fit(p3train_data,train_labels)
LRprediction = LRclf.predict(p3dev_data)
print("P3 F1 score for Logistic Regression algorithm is ", metrics.f1_score(dev_labels, LRprediction, average='macro'))

# Fit a logistic regression model and find the optimal value for the regularization strength C using l2 regularization
parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }
LRclf = GridSearchCV(LogisticRegression(penalty='l2'), parameters)
LRclf.fit(p3train_data,train_labels)

# Print the best estimator
print(LRclf.best_estimator_)
# Print the best score
print(LRclf.best_score_)
# Print the best alpha
print(LRclf.best_params_)

#############PENDING - Output the sum of the squared weight values for each class for each setting of the C parameter. 
#############PENDING - Briefly explain the relationship between the sum and the value of C.

### STUDENT END ###
#P3()
------------------------------------------------------------
#def P4():
### STUDENT START ###

p4LRclf = LogisticRegression(C=0.1, penalty='l2', class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
p4LRclf.fit(p3train_data, train_labels) 
weightvectorC1 = list(p4LRclf.coef_[0])
weightvectorC2 = list(p4LRclf.coef_[1])
weightvectorC3 = list(p4LRclf.coef_[2])
weightvectorC4 = list(p4LRclf.coef_[3])
print("Class is ", p4LRclf.classes_)

featurenames = list(p3vectorizer.get_feature_names())
max_val = []
max_idx = []
classfeatures = []
w, h = 5, 20 
classf = [[0 for x in range(w)] for y in range(h)] 
#classf = np.zeros((20, 5))
#print("Class Weights for alt.atheism")
for i in range(0, 20):
    if (i<5):
        
        max_val.append(max(weightvectorC1))
        max_idx.append(weightvectorC1.index(max_val[i]))
        classfeatures.append(featurenames[max_idx[i]])
        weightvectorC1.pop(int(max_idx[i]))
        classf[i][0] = classfeatures[i]
        classf[i][1] = max_val[i]
        #print(max_val[i])
        #print(max_idx[i])
        #print(classfeatures[i])
    
    if(i>=5 and i<10):
        max_val.append(max(weightvectorC2))
        max_idx.append(weightvectorC2.index(max_val[i]))
        classfeatures.append(featurenames[max_idx[i]])
        weightvectorC2.pop(int(max_idx[i]))
        classf[i][0] = classfeatures[i]
        classf[i][2] = max_val[i]
        #print(max_val[i])
        #print(max_idx[i])
        #print(classfeatures[i])
        
    if(i>=10 and i<15):
        max_val.append(max(weightvectorC3))
        max_idx.append(weightvectorC3.index(max_val[i]))
        classfeatures.append(featurenames[max_idx[i]])
        weightvectorC3.pop(int(max_idx[i]))
        classf[i][0] = classfeatures[i]
        classf[i][3] = max_val[i]
        #print(max_val[i])
        #print(max_idx[i])
        #print(classfeatures[i])
         
    if(i>=15):
        max_val.append(max(weightvectorC4))
        max_idx.append(weightvectorC4.index(max_val[i]))
        classfeatures.append(featurenames[max_idx[i]])
        weightvectorC4.pop(int(max_idx[i]))
        classf[i][0] = classfeatures[i]
        classf[i][4] = max_val[i]
        #print(max_val[i])
        #print(max_idx[i])
        #print(classfeatures[i])
        

print("Class Weights ",classf)
#for i in range(16, 20):
    
    
#alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc
p4LRprediction = p4LRclf.predict(p3dev_data)
# Compare predicted labels with actual labels
p4LRaccuracy = p4LRclf.score(p3dev_data, dev_labels)
#print("Predicted accuracy for Logistic Regression is "+str(p4LRaccuracy))

### STUDENT END ###
#P4()
--------------------------------------------------------
def empty_preprocessor(s):
    return s

def better_preprocessor(s):
### STUDENT START ###

    sprocessed = s;
    ##replacing sequences of numbers with a single token
    sprocessed = re.sub("[0-9]", "123", sprocessed)   

    ##removing various other non-letter characters
    sprocessed = re.sub("\W", " ", sprocessed)  

    ## shortening long words
    
    return sprocessed;
### STUDENT END ###

#def P5():
### STUDENT START ###
#Get the baseline F1
p5vectorizer = CountVectorizer(lowercase=False)
p5train_data = p5vectorizer.fit_transform(train_data)

# Use the same vectorizer as the training data, so that the same vocabulary is used
p5dev_data = p5vectorizer.transform(dev_data)

P5LRclf = LogisticRegression(C=0.1)
P5LRclf.fit(p5train_data,train_labels)
P5LRprediction = P5LRclf.predict(p5dev_data)
print("Baseline F1 score for Logistic Regression algorithm is ", metrics.f1_score(dev_labels, P5LRprediction, average='macro'))

# Preprocessing the text - stripping accents, eliminating stop words, converting all text to lowercase
#p5vectorizer = CountVectorizer(strip_accents='unicode', analyzer='word', stop_words='english', lowercase=True )
#p5train_data = p5vectorizer.fit_transform(train_data)

# Use the same vectorizer as the training data, so that the same vocabulary is used
#p5dev_data = p5vectorizer.transform(dev_data)
#P5LRclf = LogisticRegression(C=0.1)
#P5LRclf.fit(p5train_data,train_labels)
#P5LRprediction = P5LRclf.predict(p5dev_data)
#print("P5 F1 score for Logistic Regression algorithm is ", metrics.f1_score(dev_labels, P5LRprediction, average='macro'))

# Preprocessing the text - stripping accents, eliminating stop words, converting all text to lowercase
p5bvectorizer = CountVectorizer(strip_accents='unicode', analyzer='word', stop_words='english', lowercase=True, preprocessor=better_preprocessor)
p5btrain_data = p5bvectorizer.fit_transform(train_data)

# Use the same vectorizer as the training data, so that the same vocabulary is used
p5bdev_data = p5bvectorizer.transform(dev_data)
P5bLRclf = LogisticRegression(C=0.1)
P5bLRclf.fit(p5btrain_data,train_labels)
P5bLRprediction = P5bLRclf.predict(p5bdev_data)
print("P5 F1 score for Logistic Regression algorithm with preprocessor is ", metrics.f1_score(dev_labels, P5bLRprediction, average='macro'))
    
### STUDENT END ###
#P5()
---------------------------------------------------

